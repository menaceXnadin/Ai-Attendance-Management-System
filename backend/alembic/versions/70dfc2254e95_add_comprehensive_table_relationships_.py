"""Add comprehensive table relationships and new tables

Revision ID: 70dfc2254e95
Revises: 006_remove_redundant_fields
Create Date: 2025-07-13 09:31:40.725740

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '70dfc2254e95'
down_revision: Union[str, Sequence[str], None] = '006_remove_redundant_fields'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    # op.create_table('notifications',
    # sa.Column('id', sa.Integer(), nullable=False),
    # sa.Column('user_id', sa.Integer(), nullable=False),
    # sa.Column('title', sa.String(), nullable=False),
    # sa.Column('message', sa.Text(), nullable=False),
    # sa.Column('type', sa.String(), nullable=False),
    # sa.Column('is_read', sa.Boolean(), nullable=True),
    # sa.Column('action_url', sa.String(), nullable=True),
    # sa.Column('created_at', sa.DateTime(), server_default=sa.text('now()'), nullable=True),
    # sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
    # sa.PrimaryKeyConstraint('id')
    # )
    # op.create_index(op.f('ix_notifications_id'), 'notifications', ['id'], unique=False)
    # Skip creating marks table - it already exists from 007_add_simple_relationships migration
    # op.create_table('marks',
    # sa.Column('id', sa.Integer(), nullable=False),
    # sa.Column('student_id', sa.Integer(), nullable=False),
    # sa.Column('subject_id', sa.Integer(), nullable=False),
    # sa.Column('exam_type', sa.String(), nullable=False),
    # sa.Column('marks_obtained', sa.Float(), nullable=False),
    # sa.Column('total_marks', sa.Float(), nullable=False),
    # sa.Column('grade', sa.String(), nullable=True),
    # sa.Column('exam_date', sa.DateTime(), nullable=False),
    # sa.Column('created_at', sa.DateTime(), server_default=sa.text('now()'), nullable=True),
    # sa.ForeignKeyConstraint(['student_id'], ['students.id'], ),
    # sa.ForeignKeyConstraint(['subject_id'], ['subjects.id'], ),
    # sa.PrimaryKeyConstraint('id')
    # )
    # op.create_index(op.f('ix_marks_id'), 'marks', ['id'], unique=False)
    op.drop_index(op.f('idx_face_logs_created'), table_name='face_recognition_logs')
    op.drop_index(op.f('idx_face_logs_status'), table_name='face_recognition_logs')
    op.drop_table('face_recognition_logs')
    op.drop_index(op.f('idx_classes_active'), table_name='classes')
    op.drop_index(op.f('idx_classes_name_year'), table_name='classes')
    op.drop_index(op.f('idx_classes_teacher'), table_name='classes')
    op.drop_table('classes')
    # Add admin_id column as nullable first, then populate and make not null
    # Check if admin_id column already exists (from 007_add_simple_relationships migration)
    try:
        op.add_column('admins', sa.Column('admin_id', sa.String(), nullable=True))
        
        # Populate admin_id with a default value based on user_id
        op.execute("UPDATE admins SET admin_id = 'ADMIN' || LPAD(user_id::text, 4, '0')")
        
        # Now make it not null
        op.alter_column('admins', 'admin_id', nullable=False)
    except Exception:
        # Column might already exist from 007 migration, just ensure it's properly set
        pass
    # Handle permissions column type change from ARRAY to JSON
    # First add a temporary column and copy data
    op.add_column('admins', sa.Column('permissions_new', sa.JSON(), nullable=True))
    
    # Convert array data to JSON array format
    op.execute("""
        UPDATE admins 
        SET permissions_new = CASE 
            WHEN permissions IS NULL THEN NULL 
            ELSE array_to_json(permissions)::json 
        END
    """)
    
    # Drop the old column and rename new one
    op.drop_column('admins', 'permissions')
    op.alter_column('admins', 'permissions_new', new_column_name='permissions')
    op.alter_column('admins', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('admins', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.drop_index(op.f('idx_admins_user_id'), table_name='admins')
    try:
        op.create_index(op.f('ix_admins_admin_id'), 'admins', ['admin_id'], unique=True)
    except Exception:
        # Index might already exist from 007 migration
        pass
    op.create_index(op.f('ix_admins_id'), 'admins', ['id'], unique=False)
    op.drop_constraint(op.f('admins_user_id_fkey'), 'admins', type_='foreignkey')
    op.create_foreign_key(None, 'admins', 'users', ['user_id'], ['id'])
    op.add_column('ai_insights', sa.Column('confidence', sa.Float(), nullable=True))
    op.add_column('ai_insights', sa.Column('is_active', sa.Boolean(), nullable=True))
    op.alter_column('ai_insights', 'data',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=True)
    op.alter_column('ai_insights', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('ai_insights', 'expires_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True)
    op.drop_index(op.f('idx_ai_insights_active'), table_name='ai_insights', postgresql_where='(is_archived = false)')
    op.drop_index(op.f('idx_ai_insights_priority'), table_name='ai_insights')
    op.drop_index(op.f('idx_ai_insights_student'), table_name='ai_insights')
    op.drop_index(op.f('idx_ai_insights_type'), table_name='ai_insights')
    op.drop_index(op.f('idx_ai_insights_unread'), table_name='ai_insights', postgresql_where='(is_read = false)')
    op.create_index(op.f('ix_ai_insights_id'), 'ai_insights', ['id'], unique=False)
    op.drop_constraint(op.f('ai_insights_student_id_fkey'), 'ai_insights', type_='foreignkey')
    op.create_foreign_key(None, 'ai_insights', 'students', ['student_id'], ['id'])
    op.drop_column('ai_insights', 'is_archived')
    op.drop_column('ai_insights', 'updated_at')
    op.drop_column('ai_insights', 'confidence_score')
    op.drop_column('ai_insights', 'is_read')
    op.drop_column('ai_insights', 'priority')
    try:
        op.add_column('attendance_records', sa.Column('subject_id', sa.Integer(), nullable=True))
    except Exception:
        # Column might already exist from 007 migration
        pass
    op.alter_column('attendance_records', 'date',
               existing_type=sa.DATE(),
               type_=sa.DateTime(),
               existing_nullable=False)
    op.alter_column('attendance_records', 'status',
               existing_type=sa.VARCHAR(length=20),
               nullable=False,
               existing_server_default=sa.text("'present'::character varying"))
    op.alter_column('attendance_records', 'confidence_score',
               existing_type=sa.NUMERIC(precision=3, scale=2),
               type_=sa.Float(),
               existing_nullable=True)
    op.alter_column('attendance_records', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.drop_index(op.f('idx_attendance_date'), table_name='attendance_records')
    op.drop_index(op.f('idx_attendance_method'), table_name='attendance_records')
    op.drop_index(op.f('idx_attendance_status'), table_name='attendance_records')
    op.drop_index(op.f('idx_attendance_student_date'), table_name='attendance_records')
    op.create_index(op.f('ix_attendance_records_id'), 'attendance_records', ['id'], unique=False)
    op.drop_constraint(op.f('attendance_records_student_id_fkey'), 'attendance_records', type_='foreignkey')
    op.create_foreign_key(None, 'attendance_records', 'students', ['student_id'], ['id'])
    op.create_foreign_key(None, 'attendance_records', 'subjects', ['subject_id'], ['id'])
    op.drop_column('attendance_records', 'updated_at')
    op.drop_column('attendance_records', 'method')
    op.drop_column('attendance_records', 'location')
    op.drop_column('attendance_records', 'time_out')
    op.drop_column('attendance_records', 'time_in')
    op.alter_column('students', 'face_encoding',
               existing_type=postgresql.BYTEA(),
               type_=sa.JSON(),
               existing_nullable=True)
    op.alter_column('students', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('students', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.drop_index(op.f('idx_students_class_year'), table_name='students')
    op.drop_index(op.f('idx_students_student_id'), table_name='students')
    op.drop_index(op.f('idx_students_user_id'), table_name='students')
    op.drop_constraint(op.f('students_student_id_key'), 'students', type_='unique')
    op.create_index(op.f('ix_students_id'), 'students', ['id'], unique=False)
    op.create_index(op.f('ix_students_student_id'), 'students', ['student_id'], unique=True)
    op.drop_constraint(op.f('students_user_id_fkey'), 'students', type_='foreignkey')
    op.create_foreign_key(None, 'students', 'users', ['user_id'], ['id'])
    try:
        op.add_column('subjects', sa.Column('updated_at', sa.DateTime(), server_default=sa.text('now()'), nullable=True))
    except Exception:
        # Column might already exist from 007 migration
        pass
    op.drop_constraint(op.f('subjects_code_key'), 'subjects', type_='unique')
    op.create_index(op.f('ix_subjects_code'), 'subjects', ['code'], unique=True)
    op.alter_column('users', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('users', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.drop_index(op.f('idx_users_email'), table_name='users')
    op.drop_index(op.f('idx_users_role'), table_name='users')
    op.drop_constraint(op.f('users_email_key'), 'users', type_='unique')
    op.create_index(op.f('ix_users_email'), 'users', ['email'], unique=True)
    op.create_index(op.f('ix_users_id'), 'users', ['id'], unique=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_users_id'), table_name='users')
    op.drop_index(op.f('ix_users_email'), table_name='users')
    op.create_unique_constraint(op.f('users_email_key'), 'users', ['email'], postgresql_nulls_not_distinct=False)
    op.create_index(op.f('idx_users_role'), 'users', ['role'], unique=False)
    op.create_index(op.f('idx_users_email'), 'users', ['email'], unique=False)
    op.alter_column('users', 'updated_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('users', 'created_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.drop_index(op.f('ix_subjects_code'), table_name='subjects')
    op.create_unique_constraint(op.f('subjects_code_key'), 'subjects', ['code'], postgresql_nulls_not_distinct=False)
    op.drop_column('subjects', 'updated_at')
    op.drop_constraint(None, 'students', type_='foreignkey')
    op.create_foreign_key(op.f('students_user_id_fkey'), 'students', 'users', ['user_id'], ['id'], ondelete='CASCADE')
    op.drop_index(op.f('ix_students_student_id'), table_name='students')
    op.drop_index(op.f('ix_students_id'), table_name='students')
    op.create_unique_constraint(op.f('students_student_id_key'), 'students', ['student_id'], postgresql_nulls_not_distinct=False)
    op.create_index(op.f('idx_students_user_id'), 'students', ['user_id'], unique=False)
    op.create_index(op.f('idx_students_student_id'), 'students', ['student_id'], unique=False)
    op.create_index(op.f('idx_students_class_year'), 'students', ['class_name', 'year'], unique=False)
    op.alter_column('students', 'updated_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('students', 'created_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('students', 'face_encoding',
               existing_type=sa.JSON(),
               type_=postgresql.BYTEA(),
               existing_nullable=True)
    op.add_column('attendance_records', sa.Column('time_in', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True))
    op.add_column('attendance_records', sa.Column('time_out', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True))
    op.add_column('attendance_records', sa.Column('location', sa.VARCHAR(length=100), autoincrement=False, nullable=True))
    op.add_column('attendance_records', sa.Column('method', sa.VARCHAR(length=20), server_default=sa.text("'manual'::character varying"), autoincrement=False, nullable=True))
    op.add_column('attendance_records', sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True))
    op.drop_constraint(None, 'attendance_records', type_='foreignkey')
    op.drop_constraint(None, 'attendance_records', type_='foreignkey')
    op.create_foreign_key(op.f('attendance_records_student_id_fkey'), 'attendance_records', 'students', ['student_id'], ['id'], ondelete='CASCADE')
    op.drop_index(op.f('ix_attendance_records_id'), table_name='attendance_records')
    op.create_index(op.f('idx_attendance_student_date'), 'attendance_records', ['student_id', 'date'], unique=False)
    op.create_index(op.f('idx_attendance_status'), 'attendance_records', ['status'], unique=False)
    op.create_index(op.f('idx_attendance_method'), 'attendance_records', ['method'], unique=False)
    op.create_index(op.f('idx_attendance_date'), 'attendance_records', ['date'], unique=False)
    op.alter_column('attendance_records', 'created_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('attendance_records', 'confidence_score',
               existing_type=sa.Float(),
               type_=sa.NUMERIC(precision=3, scale=2),
               existing_nullable=True)
    op.alter_column('attendance_records', 'status',
               existing_type=sa.VARCHAR(length=20),
               nullable=True,
               existing_server_default=sa.text("'present'::character varying"))
    op.alter_column('attendance_records', 'date',
               existing_type=sa.DateTime(),
               type_=sa.DATE(),
               existing_nullable=False)
    op.drop_column('attendance_records', 'subject_id')
    op.add_column('ai_insights', sa.Column('priority', sa.VARCHAR(length=20), server_default=sa.text("'medium'::character varying"), autoincrement=False, nullable=True))
    op.add_column('ai_insights', sa.Column('is_read', sa.BOOLEAN(), server_default=sa.text('false'), autoincrement=False, nullable=True))
    op.add_column('ai_insights', sa.Column('confidence_score', sa.NUMERIC(precision=3, scale=2), autoincrement=False, nullable=True))
    op.add_column('ai_insights', sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True))
    op.add_column('ai_insights', sa.Column('is_archived', sa.BOOLEAN(), server_default=sa.text('false'), autoincrement=False, nullable=True))
    op.drop_constraint(None, 'ai_insights', type_='foreignkey')
    op.create_foreign_key(op.f('ai_insights_student_id_fkey'), 'ai_insights', 'students', ['student_id'], ['id'], ondelete='CASCADE')
    op.drop_index(op.f('ix_ai_insights_id'), table_name='ai_insights')
    op.create_index(op.f('idx_ai_insights_unread'), 'ai_insights', ['is_read'], unique=False, postgresql_where='(is_read = false)')
    op.create_index(op.f('idx_ai_insights_type'), 'ai_insights', ['insight_type'], unique=False)
    op.create_index(op.f('idx_ai_insights_student'), 'ai_insights', ['student_id'], unique=False)
    op.create_index(op.f('idx_ai_insights_priority'), 'ai_insights', ['priority'], unique=False)
    op.create_index(op.f('idx_ai_insights_active'), 'ai_insights', ['is_archived', 'expires_at'], unique=False, postgresql_where='(is_archived = false)')
    op.alter_column('ai_insights', 'expires_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True)
    op.alter_column('ai_insights', 'created_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('ai_insights', 'data',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True)
    op.drop_column('ai_insights', 'is_active')
    op.drop_column('ai_insights', 'confidence')
    op.drop_constraint(None, 'admins', type_='foreignkey')
    op.create_foreign_key(op.f('admins_user_id_fkey'), 'admins', 'users', ['user_id'], ['id'], ondelete='CASCADE')
    op.drop_index(op.f('ix_admins_id'), table_name='admins')
    op.drop_index(op.f('ix_admins_admin_id'), table_name='admins')
    op.create_index(op.f('idx_admins_user_id'), 'admins', ['user_id'], unique=False)
    op.alter_column('admins', 'updated_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('admins', 'created_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
    op.alter_column('admins', 'permissions',
               existing_type=sa.JSON(),
               type_=postgresql.ARRAY(sa.TEXT()),
               existing_nullable=True)
    op.drop_column('admins', 'admin_id')
    op.create_table('classes',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('class_name', sa.VARCHAR(length=100), autoincrement=False, nullable=False),
    sa.Column('subject', sa.VARCHAR(length=100), autoincrement=False, nullable=False),
    sa.Column('teacher_name', sa.VARCHAR(length=255), autoincrement=False, nullable=True),
    sa.Column('room_number', sa.VARCHAR(length=50), autoincrement=False, nullable=True),
    sa.Column('start_time', postgresql.TIME(), autoincrement=False, nullable=False),
    sa.Column('end_time', postgresql.TIME(), autoincrement=False, nullable=False),
    sa.Column('days_of_week', postgresql.ARRAY(sa.INTEGER()), autoincrement=False, nullable=True),
    sa.Column('academic_year', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('semester', sa.VARCHAR(length=20), autoincrement=False, nullable=True),
    sa.Column('is_active', sa.BOOLEAN(), server_default=sa.text('true'), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name=op.f('classes_pkey'))
    )
    op.create_index(op.f('idx_classes_teacher'), 'classes', ['teacher_name'], unique=False)
    op.create_index(op.f('idx_classes_name_year'), 'classes', ['class_name', 'academic_year'], unique=False)
    op.create_index(op.f('idx_classes_active'), 'classes', ['is_active'], unique=False)
    op.create_table('face_recognition_logs',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('image_path', sa.VARCHAR(length=500), autoincrement=False, nullable=True),
    sa.Column('detected_faces', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=True),
    sa.Column('recognized_students', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=True),
    sa.Column('unrecognized_faces', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=True),
    sa.Column('processing_time_ms', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('confidence_scores', postgresql.ARRAY(sa.NUMERIC(precision=3, scale=2)), autoincrement=False, nullable=True),
    sa.Column('error_message', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('status', sa.VARCHAR(length=20), server_default=sa.text("'success'::character varying"), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name=op.f('face_recognition_logs_pkey'))
    )
    op.create_index(op.f('idx_face_logs_status'), 'face_recognition_logs', ['status'], unique=False)
    op.create_index(op.f('idx_face_logs_created'), 'face_recognition_logs', ['created_at'], unique=False)
    # Skip dropping marks table - it's managed by 007_add_simple_relationships migration
    # op.drop_index(op.f('ix_marks_id'), table_name='marks')
    # op.drop_table('marks')
    op.drop_index(op.f('ix_notifications_id'), table_name='notifications')
    op.drop_table('notifications')
    # ### end Alembic commands ###
